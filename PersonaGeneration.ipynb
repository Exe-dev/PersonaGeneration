{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "173319109fbdc3b9e6669d3e6b9b4c0d8de214a81d3d8a11fbee43e8362bce4b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Rules of persona\r\n",
    "+ Each sentence must contain between 4 and 20 words or punctuation marks.\r\n",
    "+ It contains either the word I or my.\r\n",
    "+ At least one verb, and (iv) at least one noun, pronoun or adjective."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example Dialogue with persona\n",
    "- Persona: [“I like sport”, “I work a lot”]\n",
    "- Context: “I love running.”\n",
    "- Response: “Me too! But only on weekends.”"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "{\r\n",
    "    \r\n",
    "    \"dialog\": [[\"没有 钱   万万 不行 ！ ~\"], [\"现实 就是 如此\"]], \r\n",
    "    \r\n",
    "    \"profile\": [{\"tag\": [\"漫画;旅遊;星座\"], \"loc\": \"广东 广州\", \"gender\": \"male\"}, {\"tag\": [\"\"], \"loc\": \"\", \"gender\": \"\"}], \r\n",
    "    \r\n",
    "    \"uid\": [0, 1]\r\n",
    "\r\n",
    "}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "{\r\n",
    "    \r\n",
    "    \"dialog\": [[\"For what it's worth, I don't have a problem with it.\"], [\"My apologies.  I did not have any problems with it, but I will be more careful in the future.\"]], \r\n",
    "    \r\n",
    "    \"profile\": [{\"tag\": [], \"loc\": \"\", \"gender\": \"\"}, {\"tag\": [\"i did not have any problems with it, but i will be more careful in the future.\"], \r\n",
    "    \r\n",
    "    \"loc\": \"\", \"gender\": \"\"}], \r\n",
    "    \r\n",
    "    \"uid\": [0, 1]\r\n",
    "\r\n",
    "}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test_data Example\r\n",
    "{\"uid\": [0, 1, 2], \"dialog\": [[\"剧烈运动 是 吧\"], [\"各种 剧烈运动\"], [\"... 姐 最近 有点 寂寞 过头 了 ...\"]], \"responder_profile\": {\"loc\": \"海南\", \"gender\": \"female\", \"tag\": \"美食;宅;80后\"}, \"profile\": [{\"loc\": \"天津 滨海新区\", \"gender\": \"male\", \"tag\": \"\"}, {\"loc\": \"海南\", \"gender\": \"female\", \"tag\": \"美食;宅;80后\"}, {\"loc\": \"安徽 合肥\", \"gender\": \"male\", \"tag\": \"游戏动漫;双子座;宅;音乐;90后;WOW台服众\"}], \"golden_response\": [\"可不是 ， 我 又 不 像 你 ， 有 女神 。\"]}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constant Value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "source": [
    "NPARTITIONS = 1000\r\n",
    "PATH = \"./reddit_data/*/*.json\"\r\n",
    "SCHEDULER = \"threads\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "source": [
    "import pandas as pd \r\n",
    "import json\r\n",
    "import bz2\r\n",
    "from tqdm import tqdm\r\n",
    "import glob\r\n",
    "import dask.dataframe as dd\r\n",
    "from dask.diagnostics import ProgressBar\r\n",
    "import spacy\r\n",
    "import os\r\n",
    "import redditcleaner\r\n",
    "import neuralcoref"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "source": [
    "tqdm.pandas()\r\n",
    "ProgressBar().register()\r\n",
    "nlp = spacy.load('en_core_web_sm')\r\n",
    "neuralcoref.add_to_pipe(nlp)\r\n",
    "\r\n",
    "#doc1 = nlp('My sister has a dog. She loves him.')\r\n",
    "#print(doc1._.coref_resolved)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x14c6f3a6910>"
      ]
     },
     "metadata": {},
     "execution_count": 336
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "source": [
    "if(not os.path.exists(\"./outputs\")):\r\n",
    "    os.makedirs(\"./outputs/\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "source": [
    "version = len([f for f in os.listdir(\"./outputs\") if \"persona\" in f])\r\n",
    "version"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 338
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# reddit_data下の全てのjsonファイルを読み込む"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "source": [
    "list_bz2_file = glob.glob(PATH)\r\n",
    "list_reddit_conversation = []\r\n",
    "list_bz2_file"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./reddit_data\\\\2007\\\\RC_2007-10.json']"
      ]
     },
     "metadata": {},
     "execution_count": 339
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "source": [
    "print(\"----------read input json files----------\")\r\n",
    "for i in tqdm(range(0,len(list_bz2_file))):\r\n",
    "    with open(list_bz2_file[i], mode=\"r\", encoding=\"shift-jis\") as f:\r\n",
    "        for line in f.readlines():\r\n",
    "            dic=json.loads(line)\r\n",
    "            list_reddit_conversation.append(dic)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------read input json files----------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "source": [
    "df_reddit_conversation = pd.DataFrame(list_reddit_conversation)\r\n",
    "df_reddit_conversation = df_reddit_conversation[df_reddit_conversation[\"author\"]!=\"[deleted]\"]\r\n",
    "df_reddit_conversation[\"body\"] = df_reddit_conversation[\"body\"].progress_map(lambda x:redditcleaner.clean(str(x)))\r\n",
    "df_reddit_conversation[\"body\"] = df_reddit_conversation[\"body\"].replace([\"&lt\",\"&gt\",\"&amp\"],[\"\",\"\",\"\"])\r\n",
    "df_reddit_conversation[\"body\"] = df_reddit_conversation[\"body\"].replace([\"\\\\n+\",\"\\\\r+\",\"////\",\"”\",\"’\"],[\"\",\"\",\"\",\"\",\"\"], regex=True)\r\n",
    "df_reddit_conversation.to_csv(f\"./outputs/AllConversation{version}.csv\")\r\n",
    "df_reddit_conversation.head(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9993/9993 [00:00<00:00, 35808.60it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    parent_id created_utc  ups  controversiality distinguished subreddit_id  \\\n",
       "0    t3_5yba3  1192450635    1                 0          None         t5_6   \n",
       "1    t3_5yba3  1192450639    2                 0          None         t5_6   \n",
       "2  t1_c02999p  1192450643    0                 0          None         t5_6   \n",
       "4  t1_c0299ah  1192450646    3                 0          None         t5_6   \n",
       "5    t3_5yba3  1192450656    1                 0          None         t5_6   \n",
       "\n",
       "        id  downs  archived   link_id  ...          author score_hidden  \\\n",
       "0  c0299an      0      True  t3_5yba3  ...         bostich        False   \n",
       "1  c0299ao      0      True  t3_5yba3  ...  igiveyoumylife        False   \n",
       "2  c0299ap      0      True  t3_5yba3  ...            Arve        False   \n",
       "4  c0299ar      0      True  t3_5yba3  ...       gigaquack        False   \n",
       "5  c0299as      0      True  t3_5yba3  ...         Percept        False   \n",
       "\n",
       "                                                body gilded  \\\n",
       "0                                               test      0   \n",
       "1  much smoother. Im just glad reddit is back, re...      0   \n",
       "2  Can we please deprecate the word \"Ajax\" now? (...      0   \n",
       "4         Oh, I see. Fancy schmancy \"submitting....\"      0   \n",
       "5                                        testing ...      0   \n",
       "\n",
       "   author_flair_text   subreddit edited author_flair_css_class        name  \\\n",
       "0               None  reddit.com  False                   None  t1_c0299an   \n",
       "1               None  reddit.com  False                   None  t1_c0299ao   \n",
       "2               None  reddit.com  False                   None  t1_c0299ap   \n",
       "4               None  reddit.com  False                   None  t1_c0299ar   \n",
       "5               None  reddit.com  False                   None  t1_c0299as   \n",
       "\n",
       "  retrieved_on  \n",
       "0   1427426409  \n",
       "1   1427426409  \n",
       "2   1427426409  \n",
       "4   1427426409  \n",
       "5   1427426409  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>id</th>\n",
       "      <th>downs</th>\n",
       "      <th>archived</th>\n",
       "      <th>link_id</th>\n",
       "      <th>...</th>\n",
       "      <th>author</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>body</th>\n",
       "      <th>gilded</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>edited</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>name</th>\n",
       "      <th>retrieved_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>1192450635</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>t5_6</td>\n",
       "      <td>c0299an</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>...</td>\n",
       "      <td>bostich</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t1_c0299an</td>\n",
       "      <td>1427426409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>1192450639</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>t5_6</td>\n",
       "      <td>c0299ao</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>...</td>\n",
       "      <td>igiveyoumylife</td>\n",
       "      <td>False</td>\n",
       "      <td>much smoother. Im just glad reddit is back, re...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t1_c0299ao</td>\n",
       "      <td>1427426409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_c02999p</td>\n",
       "      <td>1192450643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>t5_6</td>\n",
       "      <td>c0299ap</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>...</td>\n",
       "      <td>Arve</td>\n",
       "      <td>False</td>\n",
       "      <td>Can we please deprecate the word \"Ajax\" now? (...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t1_c0299ap</td>\n",
       "      <td>1427426409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_c0299ah</td>\n",
       "      <td>1192450646</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>t5_6</td>\n",
       "      <td>c0299ar</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>...</td>\n",
       "      <td>gigaquack</td>\n",
       "      <td>False</td>\n",
       "      <td>Oh, I see. Fancy schmancy \"submitting....\"</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t1_c0299ar</td>\n",
       "      <td>1427426409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>1192450656</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>t5_6</td>\n",
       "      <td>c0299as</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>...</td>\n",
       "      <td>Percept</td>\n",
       "      <td>False</td>\n",
       "      <td>testing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t1_c0299as</td>\n",
       "      <td>1427426409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 341
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "source": [
    "df_reddit_conversation[df_reddit_conversation[\"body\"].str.contains(\"”\")]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\\n              ...\\n              nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\\n             dtype='float64', length=4159)] are in the [columns]\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-353-ef09cd0aab26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_reddit_conversation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_reddit_conversation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"body\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Float64Index([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\\n              ...\\n              nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\\n             dtype='float64', length=4159)] are in the [columns]\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 会話ペアの作成"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "source": [
    "df_reddit_conversation[\"removed_prefix_parent_id\"] = df_reddit_conversation[\"parent_id\"].str.replace(\"t\\d_\",\"\")\r\n",
    "df_reddit_conversation[\"parent_body\"] = df_reddit_conversation[df_reddit_conversation[\"removed_prefix_parent_id\"]==df_reddit_conversation[\"id\"]][\"body\"]\r\n",
    "df_reddit_conversation[\"body\"] = df_reddit_conversation[\"body\"].str.replace('\\\"','’')\r\n",
    "df_reddit_conversation[\"parent_body\"] = df_reddit_conversation[\"parent_body\"].str.replace('\\\"','’')\r\n",
    "df_reddit_conversation = pd.merge(df_reddit_conversation,df_reddit_conversation[[\"id\",\"body\"]].rename(columns={\"id\":\"parent_id\",\"body\":\"parent_body\"}),left_on=\"removed_prefix_parent_id\",right_on=\"parent_id\").drop(columns=[\"parent_body_x\",\"parent_id_y\"]).rename(columns={\"parent_body_y\":\"parent_body\"})\r\n",
    "df_reddit_conversation = df_reddit_conversation.dropna(subset=[\"parent_body\"]).sort_values([\"author\"]).reset_index(drop=True)\r\n",
    "df_reddit_conversation[\"original_body\"] = df_reddit_conversation[\"body\"]\r\n",
    "df_reddit_conversation[\"original_parent_body\"] = df_reddit_conversation[\"parent_body\"]\r\n",
    "df_reddit_conversation = df_reddit_conversation[[\"body\",\"parent_body\",\"original_body\",\"original_parent_body\",\"ups\",\"author\"]]\r\n",
    "df_reddit_conversation"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-342-15e556bf2943>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_reddit_conversation[\"removed_prefix_parent_id\"] = df_reddit_conversation[\"parent_id\"].str.replace(\"t\\d_\",\"\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   body  \\\n",
       "0     I'd like to agree with you, but did you see wh...   \n",
       "1             Sitting at 22. Now you can begin shaving.   \n",
       "2                            that was subtle... thanks.   \n",
       "3     I don't have to prove anything. I can ask any ...   \n",
       "4     AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...   \n",
       "...                                                 ...   \n",
       "4154  Nope. Months of development, a day of downtime...   \n",
       "4155  Thanks for that- I always assumed the kinetic ...   \n",
       "4156                                                 No   \n",
       "4157  http://www.fff.org/comment/com0311c.asp maybe ...   \n",
       "4158  ’social’ added to ’problems’ do not have the s...   \n",
       "\n",
       "                                            parent_body  \\\n",
       "0     Wrong. You'd better have an idea of why the gu...   \n",
       "1               Sorry, default 25'er front page only. P   \n",
       "2      genetically identical fish are sending out tw...   \n",
       "3     Again, prove that. If they think they are neve...   \n",
       "4                                        Thanks, repug.   \n",
       "...                                                 ...   \n",
       "4154  Is anything else different? Surely there's mor...   \n",
       "4155  Not that it changes your point, but I think yo...   \n",
       "4156  Can we please deprecate the word ’Ajax’ now? (...   \n",
       "4157  Wow What a shocker After Saddam attempted to a...   \n",
       "4158  Oh okay, you're right, let's just cancel all s...   \n",
       "\n",
       "                                          original_body  \\\n",
       "0     I'd like to agree with you, but did you see wh...   \n",
       "1             Sitting at 22. Now you can begin shaving.   \n",
       "2                            that was subtle... thanks.   \n",
       "3     I don't have to prove anything. I can ask any ...   \n",
       "4     AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...   \n",
       "...                                                 ...   \n",
       "4154  Nope. Months of development, a day of downtime...   \n",
       "4155  Thanks for that- I always assumed the kinetic ...   \n",
       "4156                                                 No   \n",
       "4157  http://www.fff.org/comment/com0311c.asp maybe ...   \n",
       "4158  ’social’ added to ’problems’ do not have the s...   \n",
       "\n",
       "                                   original_parent_body  ups       author  \n",
       "0     Wrong. You'd better have an idea of why the gu...   16      48klocs  \n",
       "1               Sorry, default 25'er front page only. P    7      54gy6dm  \n",
       "2      genetically identical fish are sending out tw...    4      54gy6dm  \n",
       "3     Again, prove that. If they think they are neve...    1  60MinuteMan  \n",
       "4                                        Thanks, repug.    0  60MinuteMan  \n",
       "...                                                 ...  ...          ...  \n",
       "4154  Is anything else different? Surely there's mor...    4   zoomzoom83  \n",
       "4155  Not that it changes your point, but I think yo...    4   zoomzoom83  \n",
       "4156  Can we please deprecate the word ’Ajax’ now? (...    2   zoomzoom83  \n",
       "4157  Wow What a shocker After Saddam attempted to a...    1        zorno  \n",
       "4158  Oh okay, you're right, let's just cancel all s...    2      zouhair  \n",
       "\n",
       "[4159 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>parent_body</th>\n",
       "      <th>original_body</th>\n",
       "      <th>original_parent_body</th>\n",
       "      <th>ups</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to agree with you, but did you see wh...</td>\n",
       "      <td>Wrong. You'd better have an idea of why the gu...</td>\n",
       "      <td>I'd like to agree with you, but did you see wh...</td>\n",
       "      <td>Wrong. You'd better have an idea of why the gu...</td>\n",
       "      <td>16</td>\n",
       "      <td>48klocs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sitting at 22. Now you can begin shaving.</td>\n",
       "      <td>Sorry, default 25'er front page only. P</td>\n",
       "      <td>Sitting at 22. Now you can begin shaving.</td>\n",
       "      <td>Sorry, default 25'er front page only. P</td>\n",
       "      <td>7</td>\n",
       "      <td>54gy6dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that was subtle... thanks.</td>\n",
       "      <td>genetically identical fish are sending out tw...</td>\n",
       "      <td>that was subtle... thanks.</td>\n",
       "      <td>genetically identical fish are sending out tw...</td>\n",
       "      <td>4</td>\n",
       "      <td>54gy6dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't have to prove anything. I can ask any ...</td>\n",
       "      <td>Again, prove that. If they think they are neve...</td>\n",
       "      <td>I don't have to prove anything. I can ask any ...</td>\n",
       "      <td>Again, prove that. If they think they are neve...</td>\n",
       "      <td>1</td>\n",
       "      <td>60MinuteMan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...</td>\n",
       "      <td>Thanks, repug.</td>\n",
       "      <td>AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...</td>\n",
       "      <td>Thanks, repug.</td>\n",
       "      <td>0</td>\n",
       "      <td>60MinuteMan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>Nope. Months of development, a day of downtime...</td>\n",
       "      <td>Is anything else different? Surely there's mor...</td>\n",
       "      <td>Nope. Months of development, a day of downtime...</td>\n",
       "      <td>Is anything else different? Surely there's mor...</td>\n",
       "      <td>4</td>\n",
       "      <td>zoomzoom83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>Thanks for that- I always assumed the kinetic ...</td>\n",
       "      <td>Not that it changes your point, but I think yo...</td>\n",
       "      <td>Thanks for that- I always assumed the kinetic ...</td>\n",
       "      <td>Not that it changes your point, but I think yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>zoomzoom83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>No</td>\n",
       "      <td>Can we please deprecate the word ’Ajax’ now? (...</td>\n",
       "      <td>No</td>\n",
       "      <td>Can we please deprecate the word ’Ajax’ now? (...</td>\n",
       "      <td>2</td>\n",
       "      <td>zoomzoom83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>http://www.fff.org/comment/com0311c.asp maybe ...</td>\n",
       "      <td>Wow What a shocker After Saddam attempted to a...</td>\n",
       "      <td>http://www.fff.org/comment/com0311c.asp maybe ...</td>\n",
       "      <td>Wow What a shocker After Saddam attempted to a...</td>\n",
       "      <td>1</td>\n",
       "      <td>zorno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>’social’ added to ’problems’ do not have the s...</td>\n",
       "      <td>Oh okay, you're right, let's just cancel all s...</td>\n",
       "      <td>’social’ added to ’problems’ do not have the s...</td>\n",
       "      <td>Oh okay, you're right, let's just cancel all s...</td>\n",
       "      <td>2</td>\n",
       "      <td>zouhair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4159 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 342
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "source": [
    "def CreatePersona(body: str):\r\n",
    "    doc = nlp(body.lower())\r\n",
    "    # 文ごとに分割\r\n",
    "    persona = [str(sentence) for sentence in doc.sents if IsPersona(str(sentence))]\r\n",
    "    return persona"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "source": [
    "def IsPersona(sentence: str):\r\n",
    "    # 以下の3つの条件を満たすものをペルソナとする\r\n",
    "    # 1.文の単語数が4-20の間\r\n",
    "    # 2.I か my　が含まれている\r\n",
    "    # 3.少なくとも1つの動詞と，名詞，代名詞，形容詞のいずれかが含まれている\r\n",
    "    words = [str(word) for word in nlp(sentence.strip())]\r\n",
    "    poses = [token.pos_ for token in nlp(sentence.strip())]\r\n",
    "    return (\r\n",
    "        (4 <= len(words) <= 20)&\r\n",
    "        (not set([\"i\",\"my\"]).isdisjoint(set(words)))&\r\n",
    "        ((\"VERB\" in poses)&(not set([\"NOUN\", \"ADJ\", \"PROPN\"]).isdisjoint(set(poses))))\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "source": [
    "def create_json(row):\r\n",
    "    return {\r\n",
    "        \"dialog\":row[\"dialog\"],\r\n",
    "        \"profile\":[\r\n",
    "            {\"tag\":row[\"persona\"],\r\n",
    "            \"loc\":\"\",\r\n",
    "            \"gender\":\"\"},\r\n",
    "            {\"tag\":row[\"parent_persona\"],\r\n",
    "            \"loc\":\"\",\r\n",
    "            \"gender\":\"\"}\r\n",
    "        ],\r\n",
    "        \"uid\":[0,1]\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ペルソナの作成"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "source": [
    "print(\"----------create conversation pair ----------\")\r\n",
    "ddf_reddit_conversation = dd.from_pandas(data=df_reddit_conversation, npartitions=NPARTITIONS)\r\n",
    "ddf_reddit_conversation[\"persona\"] = ddf_reddit_conversation[\"original_body\"].map(CreatePersona)\r\n",
    "ddf_reddit_conversation[\"parent_persona\"] = ddf_reddit_conversation[\"original_parent_body\"].map(CreatePersona)\r\n",
    "ddf_reddit_conversation.query(\"persona.notnull() | parent_persona.notnull()\")\r\n",
    "#ddf_reddit_conversation[\"body\"] = ddf_reddit_conversation[\"body\"].map(lambda sentence:nlp(sentence)._.coref_resolved)\r\n",
    "#ddf_reddit_conversation[\"parent_body\"] = ddf_reddit_conversation[\"parent_body\"].map(lambda sentence:nlp(sentence)._.coref_resolved)\r\n",
    "df_reddit_conversation = ddf_reddit_conversation.compute(scheduler=SCHEDULER)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------create conversation pair ----------\n",
      "[########################################] | 100% Completed | 14min 17.0s\n",
      "[########################################] | 100% Completed | 14min 17.1s\n",
      "[########################################] | 100% Completed | 14min 17.2s\n",
      "[########################################] | 100% Completed | 14min 17.2s\n",
      "[########################################] | 100% Completed | 14min 17.2s\n",
      "[########################################] | 100% Completed | 14min 17.3s\n",
      "[########################################] | 100% Completed | 14min 17.4s\n",
      "[########################################] | 100% Completed | 14min 17.4s\n",
      "[########################################] | 100% Completed | 14min 17.5s\n",
      "[########################################] | 100% Completed | 14min 17.5s\n",
      "[########################################] | 100% Completed | 14min 17.6s\n",
      "[########################################] | 100% Completed | 14min 17.6s\n",
      "[########################################] | 100% Completed | 14min 17.8s\n",
      "[########################################] | 100% Completed | 14min 17.8s\n",
      "[########################################] | 100% Completed | 14min 17.9s\n",
      "[########################################] | 100% Completed | 14min 18.0s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "source": [
    "print(\"--------- create list ----------\")\r\n",
    "df_reddit_conversation[\"body\"] = df_reddit_conversation[\"body\"].progress_map(lambda x: [x] )\r\n",
    "df_reddit_conversation[\"parent_body\"] = df_reddit_conversation[\"parent_body\"].progress_map(lambda x: [x] )\r\n",
    "df_reddit_conversation[\"dialog\"] = [list(x) for x in zip(df_reddit_conversation[\"body\"].tolist(),df_reddit_conversation[\"parent_body\"].tolist())]\r\n",
    "df_reddit_conversation"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4159/4159 [00:00<00:00, 831661.99it/s]\n",
      "100%|██████████| 4159/4159 [00:00<00:00, 1039391.67it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------- create list ----------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   body  \\\n",
       "0     [I'd like to agree with you, but did you see w...   \n",
       "1           [Sitting at 22. Now you can begin shaving.]   \n",
       "2                          [that was subtle... thanks.]   \n",
       "3     [I don't have to prove anything. I can ask any...   \n",
       "4     [AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www....   \n",
       "...                                                 ...   \n",
       "4154  [Nope. Months of development, a day of downtim...   \n",
       "4155  [Thanks for that- I always assumed the kinetic...   \n",
       "4156                                               [No]   \n",
       "4157  [http://www.fff.org/comment/com0311c.asp maybe...   \n",
       "4158  [’social’ added to ’problems’ do not have the ...   \n",
       "\n",
       "                                            parent_body  \\\n",
       "0     [Wrong. You'd better have an idea of why the g...   \n",
       "1             [Sorry, default 25'er front page only. P]   \n",
       "2     [ genetically identical fish are sending out t...   \n",
       "3     [Again, prove that. If they think they are nev...   \n",
       "4                                      [Thanks, repug.]   \n",
       "...                                                 ...   \n",
       "4154  [Is anything else different? Surely there's mo...   \n",
       "4155  [Not that it changes your point, but I think y...   \n",
       "4156  [Can we please deprecate the word ’Ajax’ now? ...   \n",
       "4157  [Wow What a shocker After Saddam attempted to ...   \n",
       "4158  [Oh okay, you're right, let's just cancel all ...   \n",
       "\n",
       "                                          original_body  \\\n",
       "0     I'd like to agree with you, but did you see wh...   \n",
       "1             Sitting at 22. Now you can begin shaving.   \n",
       "2                            that was subtle... thanks.   \n",
       "3     I don't have to prove anything. I can ask any ...   \n",
       "4     AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...   \n",
       "...                                                 ...   \n",
       "4154  Nope. Months of development, a day of downtime...   \n",
       "4155  Thanks for that- I always assumed the kinetic ...   \n",
       "4156                                                 No   \n",
       "4157  http://www.fff.org/comment/com0311c.asp maybe ...   \n",
       "4158  ’social’ added to ’problems’ do not have the s...   \n",
       "\n",
       "                                   original_parent_body  ups       author  \\\n",
       "0     Wrong. You'd better have an idea of why the gu...   16      48klocs   \n",
       "1               Sorry, default 25'er front page only. P    7      54gy6dm   \n",
       "2      genetically identical fish are sending out tw...    4      54gy6dm   \n",
       "3     Again, prove that. If they think they are neve...    1  60MinuteMan   \n",
       "4                                        Thanks, repug.    0  60MinuteMan   \n",
       "...                                                 ...  ...          ...   \n",
       "4154  Is anything else different? Surely there's mor...    4   zoomzoom83   \n",
       "4155  Not that it changes your point, but I think yo...    4   zoomzoom83   \n",
       "4156  Can we please deprecate the word ’Ajax’ now? (...    2   zoomzoom83   \n",
       "4157  Wow What a shocker After Saddam attempted to a...    1        zorno   \n",
       "4158  Oh okay, you're right, let's just cancel all s...    2      zouhair   \n",
       "\n",
       "                                                persona  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "4154  [(in reality, i think it's a complete rewrite ...   \n",
       "4155                                                 []   \n",
       "4156                                                 []   \n",
       "4157                                                 []   \n",
       "4158                                                 []   \n",
       "\n",
       "                                         parent_persona  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3     [i think you're generalizing quite a bit witho...   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "4154  [edit: i guess that sounded kinda snotty., i r...   \n",
       "4155  [not that it changes your point, but i think y...   \n",
       "4156                                                 []   \n",
       "4157                                                 []   \n",
       "4158                                                 []   \n",
       "\n",
       "                                                 dialog  \n",
       "0     [[I'd like to agree with you, but did you see ...  \n",
       "1     [[Sitting at 22. Now you can begin shaving.], ...  \n",
       "2     [[that was subtle... thanks.], [ genetically i...  \n",
       "3     [[I don't have to prove anything. I can ask an...  \n",
       "4     [[AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www...  \n",
       "...                                                 ...  \n",
       "4154  [[Nope. Months of development, a day of downti...  \n",
       "4155  [[Thanks for that- I always assumed the kineti...  \n",
       "4156  [[No], [Can we please deprecate the word ’Ajax...  \n",
       "4157  [[http://www.fff.org/comment/com0311c.asp mayb...  \n",
       "4158  [[’social’ added to ’problems’ do not have the...  \n",
       "\n",
       "[4159 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>parent_body</th>\n",
       "      <th>original_body</th>\n",
       "      <th>original_parent_body</th>\n",
       "      <th>ups</th>\n",
       "      <th>author</th>\n",
       "      <th>persona</th>\n",
       "      <th>parent_persona</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I'd like to agree with you, but did you see w...</td>\n",
       "      <td>[Wrong. You'd better have an idea of why the g...</td>\n",
       "      <td>I'd like to agree with you, but did you see wh...</td>\n",
       "      <td>Wrong. You'd better have an idea of why the gu...</td>\n",
       "      <td>16</td>\n",
       "      <td>48klocs</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[I'd like to agree with you, but did you see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Sitting at 22. Now you can begin shaving.]</td>\n",
       "      <td>[Sorry, default 25'er front page only. P]</td>\n",
       "      <td>Sitting at 22. Now you can begin shaving.</td>\n",
       "      <td>Sorry, default 25'er front page only. P</td>\n",
       "      <td>7</td>\n",
       "      <td>54gy6dm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[Sitting at 22. Now you can begin shaving.], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[that was subtle... thanks.]</td>\n",
       "      <td>[ genetically identical fish are sending out t...</td>\n",
       "      <td>that was subtle... thanks.</td>\n",
       "      <td>genetically identical fish are sending out tw...</td>\n",
       "      <td>4</td>\n",
       "      <td>54gy6dm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[that was subtle... thanks.], [ genetically i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I don't have to prove anything. I can ask any...</td>\n",
       "      <td>[Again, prove that. If they think they are nev...</td>\n",
       "      <td>I don't have to prove anything. I can ask any ...</td>\n",
       "      <td>Again, prove that. If they think they are neve...</td>\n",
       "      <td>1</td>\n",
       "      <td>60MinuteMan</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i think you're generalizing quite a bit witho...</td>\n",
       "      <td>[[I don't have to prove anything. I can ask an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www....</td>\n",
       "      <td>[Thanks, repug.]</td>\n",
       "      <td>AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...</td>\n",
       "      <td>Thanks, repug.</td>\n",
       "      <td>0</td>\n",
       "      <td>60MinuteMan</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>[Nope. Months of development, a day of downtim...</td>\n",
       "      <td>[Is anything else different? Surely there's mo...</td>\n",
       "      <td>Nope. Months of development, a day of downtime...</td>\n",
       "      <td>Is anything else different? Surely there's mor...</td>\n",
       "      <td>4</td>\n",
       "      <td>zoomzoom83</td>\n",
       "      <td>[(in reality, i think it's a complete rewrite ...</td>\n",
       "      <td>[edit: i guess that sounded kinda snotty., i r...</td>\n",
       "      <td>[[Nope. Months of development, a day of downti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>[Thanks for that- I always assumed the kinetic...</td>\n",
       "      <td>[Not that it changes your point, but I think y...</td>\n",
       "      <td>Thanks for that- I always assumed the kinetic ...</td>\n",
       "      <td>Not that it changes your point, but I think yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>zoomzoom83</td>\n",
       "      <td>[]</td>\n",
       "      <td>[not that it changes your point, but i think y...</td>\n",
       "      <td>[[Thanks for that- I always assumed the kineti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>[No]</td>\n",
       "      <td>[Can we please deprecate the word ’Ajax’ now? ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Can we please deprecate the word ’Ajax’ now? (...</td>\n",
       "      <td>2</td>\n",
       "      <td>zoomzoom83</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[No], [Can we please deprecate the word ’Ajax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>[http://www.fff.org/comment/com0311c.asp maybe...</td>\n",
       "      <td>[Wow What a shocker After Saddam attempted to ...</td>\n",
       "      <td>http://www.fff.org/comment/com0311c.asp maybe ...</td>\n",
       "      <td>Wow What a shocker After Saddam attempted to a...</td>\n",
       "      <td>1</td>\n",
       "      <td>zorno</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[http://www.fff.org/comment/com0311c.asp mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>[’social’ added to ’problems’ do not have the ...</td>\n",
       "      <td>[Oh okay, you're right, let's just cancel all ...</td>\n",
       "      <td>’social’ added to ’problems’ do not have the s...</td>\n",
       "      <td>Oh okay, you're right, let's just cancel all s...</td>\n",
       "      <td>2</td>\n",
       "      <td>zouhair</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[’social’ added to ’problems’ do not have the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4159 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 347
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Json形式の作成"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "source": [
    "df_reddit_conversation[\"json\"] = df_reddit_conversation.progress_apply(create_json, axis=1)\r\n",
    "df_reddit_conversation"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4159/4159 [00:00<00:00, 71691.17it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   body  \\\n",
       "0     [I'd like to agree with you, but did you see w...   \n",
       "1           [Sitting at 22. Now you can begin shaving.]   \n",
       "2                          [that was subtle... thanks.]   \n",
       "3     [I don't have to prove anything. I can ask any...   \n",
       "4     [AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www....   \n",
       "...                                                 ...   \n",
       "4154  [Nope. Months of development, a day of downtim...   \n",
       "4155  [Thanks for that- I always assumed the kinetic...   \n",
       "4156                                               [No]   \n",
       "4157  [http://www.fff.org/comment/com0311c.asp maybe...   \n",
       "4158  [’social’ added to ’problems’ do not have the ...   \n",
       "\n",
       "                                            parent_body  \\\n",
       "0     [Wrong. You'd better have an idea of why the g...   \n",
       "1             [Sorry, default 25'er front page only. P]   \n",
       "2     [ genetically identical fish are sending out t...   \n",
       "3     [Again, prove that. If they think they are nev...   \n",
       "4                                      [Thanks, repug.]   \n",
       "...                                                 ...   \n",
       "4154  [Is anything else different? Surely there's mo...   \n",
       "4155  [Not that it changes your point, but I think y...   \n",
       "4156  [Can we please deprecate the word ’Ajax’ now? ...   \n",
       "4157  [Wow What a shocker After Saddam attempted to ...   \n",
       "4158  [Oh okay, you're right, let's just cancel all ...   \n",
       "\n",
       "                                          original_body  \\\n",
       "0     I'd like to agree with you, but did you see wh...   \n",
       "1             Sitting at 22. Now you can begin shaving.   \n",
       "2                            that was subtle... thanks.   \n",
       "3     I don't have to prove anything. I can ask any ...   \n",
       "4     AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...   \n",
       "...                                                 ...   \n",
       "4154  Nope. Months of development, a day of downtime...   \n",
       "4155  Thanks for that- I always assumed the kinetic ...   \n",
       "4156                                                 No   \n",
       "4157  http://www.fff.org/comment/com0311c.asp maybe ...   \n",
       "4158  ’social’ added to ’problems’ do not have the s...   \n",
       "\n",
       "                                   original_parent_body  ups       author  \\\n",
       "0     Wrong. You'd better have an idea of why the gu...   16      48klocs   \n",
       "1               Sorry, default 25'er front page only. P    7      54gy6dm   \n",
       "2      genetically identical fish are sending out tw...    4      54gy6dm   \n",
       "3     Again, prove that. If they think they are neve...    1  60MinuteMan   \n",
       "4                                        Thanks, repug.    0  60MinuteMan   \n",
       "...                                                 ...  ...          ...   \n",
       "4154  Is anything else different? Surely there's mor...    4   zoomzoom83   \n",
       "4155  Not that it changes your point, but I think yo...    4   zoomzoom83   \n",
       "4156  Can we please deprecate the word ’Ajax’ now? (...    2   zoomzoom83   \n",
       "4157  Wow What a shocker After Saddam attempted to a...    1        zorno   \n",
       "4158  Oh okay, you're right, let's just cancel all s...    2      zouhair   \n",
       "\n",
       "                                                persona  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "4154  [(in reality, i think it's a complete rewrite ...   \n",
       "4155                                                 []   \n",
       "4156                                                 []   \n",
       "4157                                                 []   \n",
       "4158                                                 []   \n",
       "\n",
       "                                         parent_persona  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3     [i think you're generalizing quite a bit witho...   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "4154  [edit: i guess that sounded kinda snotty., i r...   \n",
       "4155  [not that it changes your point, but i think y...   \n",
       "4156                                                 []   \n",
       "4157                                                 []   \n",
       "4158                                                 []   \n",
       "\n",
       "                                                 dialog  \\\n",
       "0     [[I'd like to agree with you, but did you see ...   \n",
       "1     [[Sitting at 22. Now you can begin shaving.], ...   \n",
       "2     [[that was subtle... thanks.], [ genetically i...   \n",
       "3     [[I don't have to prove anything. I can ask an...   \n",
       "4     [[AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www...   \n",
       "...                                                 ...   \n",
       "4154  [[Nope. Months of development, a day of downti...   \n",
       "4155  [[Thanks for that- I always assumed the kineti...   \n",
       "4156  [[No], [Can we please deprecate the word ’Ajax...   \n",
       "4157  [[http://www.fff.org/comment/com0311c.asp mayb...   \n",
       "4158  [[’social’ added to ’problems’ do not have the...   \n",
       "\n",
       "                                                   json  \n",
       "0     {'dialog': [['I'd like to agree with you, but ...  \n",
       "1     {'dialog': [['Sitting at 22. Now you can begin...  \n",
       "2     {'dialog': [['that was subtle... thanks.'], ['...  \n",
       "3     {'dialog': [['I don't have to prove anything. ...  \n",
       "4     {'dialog': [['AHAHHAHAHAHAHAH YOU TOTALLY SUCK...  \n",
       "...                                                 ...  \n",
       "4154  {'dialog': [['Nope. Months of development, a d...  \n",
       "4155  {'dialog': [['Thanks for that- I always assume...  \n",
       "4156  {'dialog': [['No'], ['Can we please deprecate ...  \n",
       "4157  {'dialog': [['http://www.fff.org/comment/com03...  \n",
       "4158  {'dialog': [['’social’ added to ’problems’ do ...  \n",
       "\n",
       "[4159 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>parent_body</th>\n",
       "      <th>original_body</th>\n",
       "      <th>original_parent_body</th>\n",
       "      <th>ups</th>\n",
       "      <th>author</th>\n",
       "      <th>persona</th>\n",
       "      <th>parent_persona</th>\n",
       "      <th>dialog</th>\n",
       "      <th>json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I'd like to agree with you, but did you see w...</td>\n",
       "      <td>[Wrong. You'd better have an idea of why the g...</td>\n",
       "      <td>I'd like to agree with you, but did you see wh...</td>\n",
       "      <td>Wrong. You'd better have an idea of why the gu...</td>\n",
       "      <td>16</td>\n",
       "      <td>48klocs</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[I'd like to agree with you, but did you see ...</td>\n",
       "      <td>{'dialog': [['I'd like to agree with you, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Sitting at 22. Now you can begin shaving.]</td>\n",
       "      <td>[Sorry, default 25'er front page only. P]</td>\n",
       "      <td>Sitting at 22. Now you can begin shaving.</td>\n",
       "      <td>Sorry, default 25'er front page only. P</td>\n",
       "      <td>7</td>\n",
       "      <td>54gy6dm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[Sitting at 22. Now you can begin shaving.], ...</td>\n",
       "      <td>{'dialog': [['Sitting at 22. Now you can begin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[that was subtle... thanks.]</td>\n",
       "      <td>[ genetically identical fish are sending out t...</td>\n",
       "      <td>that was subtle... thanks.</td>\n",
       "      <td>genetically identical fish are sending out tw...</td>\n",
       "      <td>4</td>\n",
       "      <td>54gy6dm</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[that was subtle... thanks.], [ genetically i...</td>\n",
       "      <td>{'dialog': [['that was subtle... thanks.'], ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I don't have to prove anything. I can ask any...</td>\n",
       "      <td>[Again, prove that. If they think they are nev...</td>\n",
       "      <td>I don't have to prove anything. I can ask any ...</td>\n",
       "      <td>Again, prove that. If they think they are neve...</td>\n",
       "      <td>1</td>\n",
       "      <td>60MinuteMan</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i think you're generalizing quite a bit witho...</td>\n",
       "      <td>[[I don't have to prove anything. I can ask an...</td>\n",
       "      <td>{'dialog': [['I don't have to prove anything. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www....</td>\n",
       "      <td>[Thanks, repug.]</td>\n",
       "      <td>AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www.n...</td>\n",
       "      <td>Thanks, repug.</td>\n",
       "      <td>0</td>\n",
       "      <td>60MinuteMan</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[AHAHHAHAHAHAHAH YOU TOTALLY SUCK. http://www...</td>\n",
       "      <td>{'dialog': [['AHAHHAHAHAHAHAH YOU TOTALLY SUCK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>[Nope. Months of development, a day of downtim...</td>\n",
       "      <td>[Is anything else different? Surely there's mo...</td>\n",
       "      <td>Nope. Months of development, a day of downtime...</td>\n",
       "      <td>Is anything else different? Surely there's mor...</td>\n",
       "      <td>4</td>\n",
       "      <td>zoomzoom83</td>\n",
       "      <td>[(in reality, i think it's a complete rewrite ...</td>\n",
       "      <td>[edit: i guess that sounded kinda snotty., i r...</td>\n",
       "      <td>[[Nope. Months of development, a day of downti...</td>\n",
       "      <td>{'dialog': [['Nope. Months of development, a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>[Thanks for that- I always assumed the kinetic...</td>\n",
       "      <td>[Not that it changes your point, but I think y...</td>\n",
       "      <td>Thanks for that- I always assumed the kinetic ...</td>\n",
       "      <td>Not that it changes your point, but I think yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>zoomzoom83</td>\n",
       "      <td>[]</td>\n",
       "      <td>[not that it changes your point, but i think y...</td>\n",
       "      <td>[[Thanks for that- I always assumed the kineti...</td>\n",
       "      <td>{'dialog': [['Thanks for that- I always assume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>[No]</td>\n",
       "      <td>[Can we please deprecate the word ’Ajax’ now? ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Can we please deprecate the word ’Ajax’ now? (...</td>\n",
       "      <td>2</td>\n",
       "      <td>zoomzoom83</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[No], [Can we please deprecate the word ’Ajax...</td>\n",
       "      <td>{'dialog': [['No'], ['Can we please deprecate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>[http://www.fff.org/comment/com0311c.asp maybe...</td>\n",
       "      <td>[Wow What a shocker After Saddam attempted to ...</td>\n",
       "      <td>http://www.fff.org/comment/com0311c.asp maybe ...</td>\n",
       "      <td>Wow What a shocker After Saddam attempted to a...</td>\n",
       "      <td>1</td>\n",
       "      <td>zorno</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[http://www.fff.org/comment/com0311c.asp mayb...</td>\n",
       "      <td>{'dialog': [['http://www.fff.org/comment/com03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>[’social’ added to ’problems’ do not have the ...</td>\n",
       "      <td>[Oh okay, you're right, let's just cancel all ...</td>\n",
       "      <td>’social’ added to ’problems’ do not have the s...</td>\n",
       "      <td>Oh okay, you're right, let's just cancel all s...</td>\n",
       "      <td>2</td>\n",
       "      <td>zouhair</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[’social’ added to ’problems’ do not have the...</td>\n",
       "      <td>{'dialog': [['’social’ added to ’problems’ do ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4159 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 348
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Outputs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "source": [
    "df_reddit_conversation.to_csv(f\"./outputs/persona{version}.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "source": [
    "list_json = df_reddit_conversation[\"json\"].tolist()\r\n",
    "with open(f\"./outputs/created_dialogues{version}.json\", \"wt\", encoding=\"utf-8\") as file:\r\n",
    "    for dic in list_json:\r\n",
    "        file.write(str(json.dumps(dic))+\"\\n\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "source": [
    "import subprocess\r\n",
    "subprocess.run(['jupyter', 'nbconvert', '--to', 'script', '*.ipynb'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CompletedProcess(args=['jupyter', 'nbconvert', '--to', 'script', '*.ipynb'], returncode=0)"
      ]
     },
     "metadata": {},
     "execution_count": 351
    }
   ],
   "metadata": {}
  }
 ]
}